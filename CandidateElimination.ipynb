{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)For a given set of training data examples stored in a .CSV file, implement and demonstrate the Candidate-Elimination algorithm to output a description of the set of all hypotheses consistent with the training examples.\n",
    "##### Author : Anantha Bhat Innanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Japan ', 'Honda', 'Blue ', '1980', 'Economy', 'Yes'), ('Japan ', 'Toyota', 'Green', '1970', 'Sports', 'No'), ('Japan ', 'Toyota', 'Blue ', '1990', 'Economy', 'Yes'), ('USA', 'Chrysler', 'Red', '1980', 'Economy', 'No'), ('Japan ', 'Honda', 'White', '1980', 'Economy', 'Yes')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# open the CSVFile and keep all rows as list of tuples\n",
    "with open('EnjoySport.csv') as csvFile:\n",
    "    examples = [tuple(line) for line in csv.reader(csvFile)]\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Japan ', 'USA'],\n",
       " ['Chrysler', 'Honda', 'Toyota'],\n",
       " ['Blue ', 'Green', 'Red', 'White'],\n",
       " ['1970', '1980', '1990'],\n",
       " ['Economy', 'Sports'],\n",
       " ['No', 'Yes']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To obtain the domain of attribute values defined in the instances X\n",
    "def get_domains(examples):\n",
    "    # set function returns the unordered collection of items with no duplicates\n",
    "    d = [set() for i in examples[0]] \n",
    "    for x in examples:\n",
    "        #Enumerate() function adds a counter to an iterable and returns it in a form of enumerate object i.e(index,value)\n",
    "        for i, xi in enumerate(x):\n",
    "            d[i].add(xi)\n",
    "    return [list(sorted(x)) for x in d]\n",
    "# Test the get_domains function\n",
    "get_domains(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat the '?' and '0' length of domain no of times\n",
    "def g_0(n):\n",
    "    return ('?',)*n\n",
    "\n",
    "def s_0(n):\n",
    "    return ('0',)*n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to check generality between two hypothesis\n",
    "def more_general(h1, h2):\n",
    "    more_general_parts = []\n",
    "    for x, y in zip(h1, h2):\n",
    "        mg = x == '?' or (x != '0' and (x == y or y == '0'))\n",
    "        more_general_parts.append(mg)\n",
    "    return all(more_general_parts) # Returns true if all elements of list or tuple are true\n",
    "\n",
    "# Function to check whether train examples are consistent with hypothesis\n",
    "def consistent(hypothesis,example):\n",
    "    return more_general(hypothesis, example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# Function to add min_generalizations\n",
    "def min_generalizations(h, x):\n",
    "    h_new = list(h)\n",
    "    for i in range(len(h)):\n",
    "        if not consistent(h[i:i+1],x[i:i+1]):\n",
    "            if h[i] != '0':\n",
    "                h_new[i] = '?'\n",
    "            else:\n",
    "                h_new[i] = x[i]\n",
    "    return [tuple(h_new)]\n",
    "\n",
    "# Function to generalize Specific hypto\n",
    "def generalize_S(x, G, S):\n",
    "    S_prev = list(S)\n",
    "    for s in S_prev:\n",
    "        if s not in S:\n",
    "            continue\n",
    "        if not consistent(s,x):\n",
    "            S.remove(s)\n",
    "            Splus = min_generalizations(s, x)\n",
    "            # Keep only generalizations that have a counterpart in G\n",
    "            S.update([h for h in Splus if any([more_general(g,h) \n",
    "                                               for g in G])])\n",
    "            # Remove from S any hypothesis more general than any other hypothesis in S\n",
    "            S.difference_update([h for h in S if \n",
    "                                 any([more_general(h, h1) \n",
    "                                      for h1 in S if h != h1])])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to add min_specializations\n",
    "def min_specializations(h, domains, x):\n",
    "    results = []\n",
    "    for i in range(len(h)):\n",
    "        if h[i] == '?':\n",
    "            for val in domains[i]:\n",
    "                if x[i] != val:\n",
    "                    h_new = h[:i] + (val,) + h[i+1:]\n",
    "                    results.append(h_new)\n",
    "        elif h[i] != '0':\n",
    "            h_new = h[:i] + ('0',) + h[i+1:]\n",
    "            results.append(h_new)\n",
    "    return results\n",
    "\n",
    "# Function to specialize General hypotheses boundary\n",
    "def specialize_G(x, domains, G, S):\n",
    "    G_prev = list(G)\n",
    "    for g in G_prev:\n",
    "        if g not in G:\n",
    "            continue\n",
    "        if consistent(g,x):\n",
    "            G.remove(g)\n",
    "            Gminus = min_specializations(g, domains, x)\n",
    "            # Keep only specializations that have a counterpart in S\n",
    "            G.update([h for h in Gminus if any([more_general(h, s)\n",
    "                                                for s in S])])\n",
    "            # Remove hypothesis less general than any other hypothesis in G\n",
    "            G.difference_update([h for h in G if \n",
    "                                 any([more_general(g1, h) \n",
    "                                      for g1 in G if h != g1])])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform CandidateElimination\n",
    "def candidate_elimination(examples):\n",
    "    domains = get_domains(examples)[:-1] \n",
    "    \n",
    "    G = set([g_0(len(domains))])\n",
    "    S = set([s_0(len(domains))])\n",
    "    i=0\n",
    "    print('All the hypotheses in General and Specific boundary are:\\n')\n",
    "    print('\\n G[{0}]:'.format(i),G)\n",
    "    print('\\n S[{0}]:'.format(i),S)\n",
    "    for xcx in examples:\n",
    "        i=i+1\n",
    "        x, cx = xcx[:-1], xcx[-1]  # Splitting data into attributes and decisions\n",
    "        if cx=='Yes': # x is positive example\n",
    "            G = {g for g in G if consistent(g,x)}\n",
    "            S = generalize_S(x, G, S)\n",
    "        else: # x is negative example\n",
    "            S = {s for s in S if not consistent(s,x)}\n",
    "            G = specialize_G(x, domains, G, S)\n",
    "        print('\\n G[{0}]:'.format(i),G)\n",
    "        print('\\n S[{0}]:'.format(i),S)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the hypotheses in General and Specific boundary are:\n",
      "\n",
      "\n",
      " G[0]: {('?', '?', '?', '?', '?')}\n",
      "\n",
      " S[0]: {('0', '0', '0', '0', '0')}\n",
      "\n",
      " G[1]: {('?', '?', '?', '?', '?')}\n",
      "\n",
      " S[1]: {('Japan ', 'Honda', 'Blue ', '1980', 'Economy')}\n",
      "\n",
      " G[2]: {('?', '?', '?', '?', 'Economy'), ('?', 'Honda', '?', '?', '?'), ('?', '?', '?', '1980', '?'), ('?', '?', 'Blue ', '?', '?')}\n",
      "\n",
      " S[2]: {('Japan ', 'Honda', 'Blue ', '1980', 'Economy')}\n",
      "\n",
      " G[3]: {('?', '?', '?', '?', 'Economy'), ('?', '?', 'Blue ', '?', '?')}\n",
      "\n",
      " S[3]: {('Japan ', '?', 'Blue ', '?', 'Economy')}\n",
      "\n",
      " G[4]: {('Japan ', '?', '?', '?', 'Economy'), ('?', '?', 'Blue ', '?', '?')}\n",
      "\n",
      " S[4]: {('Japan ', '?', 'Blue ', '?', 'Economy')}\n",
      "\n",
      " G[5]: {('Japan ', '?', '?', '?', 'Economy')}\n",
      "\n",
      " S[5]: {('Japan ', '?', '?', '?', 'Economy')}\n"
     ]
    }
   ],
   "source": [
    "#import pixiedust # Visual debugger\n",
    "#%%pixie_debugger\n",
    "candidate_elimination(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
